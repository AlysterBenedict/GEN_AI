{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd95376",
   "metadata": {},
   "source": [
    "Program 1:\n",
    "Explore pre-trained word vectors. Explore word relationships using vector arithmetic. Perform arithmetic operations and analyze results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3171bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained word vectors...\n",
      "\n",
      "Word Relationship: king - man + woman\n",
      "Most similar words to the result (excluding input words):\n",
      "queen: 0.7301\n",
      "monarch: 0.6455\n",
      "princess: 0.6156\n",
      "crown_prince: 0.5819\n",
      "prince: 0.5777\n",
      "\n",
      "Word Relationship: paris - france + germany\n",
      "Most similar words to the result (excluding input words):\n",
      "berlin: 0.4838\n",
      "german: 0.4695\n",
      "lindsay_lohan: 0.4536\n",
      "switzerland: 0.4468\n",
      "heidi: 0.4445\n",
      "\n",
      "Word Relationship: apple - fruit + carrot\n",
      "Most similar words to the result (excluding input words):\n",
      "carrots: 0.5700\n",
      "proverbial_carrot: 0.4578\n",
      "Carrot: 0.4159\n",
      "Twizzler: 0.4074\n",
      "peppermint_candy: 0.4074\n",
      "\n",
      "Similarity between 'cat' and 'dog': 0.7609\n",
      "\n",
      "Similarity between 'computer' and 'keyboard': 0.3964\n",
      "\n",
      "Similarity between 'music' and 'art': 0.4010\n",
      "\n",
      "Most similar words to 'happy':\n",
      "glad: 0.7409\n",
      "pleased: 0.6632\n",
      "ecstatic: 0.6627\n",
      "overjoyed: 0.6599\n",
      "thrilled: 0.6514\n",
      "\n",
      "Most similar words to 'sad':\n",
      "saddening: 0.7273\n",
      "Sad: 0.6611\n",
      "saddened: 0.6604\n",
      "heartbreaking: 0.6574\n",
      "disheartening: 0.6507\n",
      "\n",
      "Most similar words to 'technology':\n",
      "technologies: 0.8332\n",
      "innovations: 0.6231\n",
      "technological_innovations: 0.6102\n",
      "technol: 0.6047\n",
      "technological_advancement: 0.6036\n"
     ]
    }
   ],
   "source": [
    "# !pip install gensim numpy\n",
    "\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "\n",
    "print(\"Loading pre-trained word vectors...\")\n",
    "word_vectors = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "def explore_word_relationships(word1: str, word2: str, word3: str) -> None:\n",
    "\n",
    "    for word in (word1, word2, word3):\n",
    "        if word not in word_vectors:\n",
    "            print(f\"Error: '{word}' not found in the vocabulary.\")\n",
    "            return\n",
    "\n",
    "    vec1 = word_vectors[word1]\n",
    "    vec2 = word_vectors[word2]\n",
    "    vec3 = word_vectors[word3]\n",
    "    \n",
    "    result_vector = vec1 - vec2 + vec3\n",
    "    \n",
    "    # Retrieve most similar words\n",
    "    similar_words = word_vectors.similar_by_vector(result_vector, topn=10)\n",
    "    \n",
    "    # Exclude the input words and display the top 5 results\n",
    "    filtered_words = [(word, sim) for word, sim in similar_words if word not in {word1, word2, word3}]\n",
    "    print(f\"\\nWord Relationship: {word1} - {word2} + {word3}\")\n",
    "    print(\"Most similar words to the result (excluding input words):\")\n",
    "    for word, sim in filtered_words[:5]:\n",
    "        print(f\"{word}: {sim:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculates and prints the cosine similarity between two words.\n",
    "def analyze_similarity(word1: str, word2: str) -> None:\n",
    "    for word in (word1, word2):\n",
    "        if word not in word_vectors:\n",
    "            print(f\"Error: '{word}' not found in the vocabulary.\")\n",
    "            return  \n",
    "    similarity = word_vectors.similarity(word1, word2)\n",
    "    print(f\"\\nSimilarity between '{word1}' and '{word2}': {similarity:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Prints the top 5 words most similar to the provided word.\n",
    "def find_most_similar(word: str) -> None:\n",
    "\n",
    "    if word not in word_vectors:\n",
    "        print(f\"Error: '{word}' not found in the vocabulary.\")\n",
    "        return\n",
    "        \n",
    "    similar_words = word_vectors.most_similar(word, topn=5)\n",
    "    print(f\"\\nMost similar words to '{word}':\")\n",
    "    for similar_word, sim in similar_words:\n",
    "        print(f\"{similar_word}: {sim:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Explore word relationships via vector arithmetic\n",
    "    explore_word_relationships(\"king\", \"man\", \"woman\")\n",
    "    explore_word_relationships(\"paris\", \"france\", \"germany\")\n",
    "    explore_word_relationships(\"apple\", \"fruit\", \"carrot\")\n",
    "    \n",
    "    # Analyze similarity between word pairs\n",
    "    analyze_similarity(\"cat\", \"dog\")\n",
    "    analyze_similarity(\"computer\", \"keyboard\")\n",
    "    analyze_similarity(\"music\", \"art\")\n",
    "    \n",
    "    # Find and display most similar words for given words\n",
    "    find_most_similar(\"happy\")\n",
    "    find_most_similar(\"sad\")\n",
    "    find_most_similar(\"technology\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
